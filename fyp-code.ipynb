{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity detection on static data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader,\n",
    ")  # Gives easier dataset managment and creates mini batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('datapool.csv', 'w', newline='') as file:\n",
    "    fieldnames = ['Image', 'Label']\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for i in range(328):\n",
    "        writer.writerow({'Image': 'sit' + str(i+1) + '.png', 'Label': 0})\n",
    "    for i in range(230):\n",
    "        writer.writerow({'Image': 'stand' + str(i+1) + '.png', 'Label': 1})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             Image  Label\n",
       "0        sit1.png      0\n",
       "1        sit2.png      0\n",
       "2        sit3.png      0\n",
       "3        sit4.png      0\n",
       "4        sit5.png      0\n",
       "..            ...    ...\n",
       "553  stand226.png      1\n",
       "554  stand227.png      1\n",
       "555  stand228.png      1\n",
       "556  stand229.png      1\n",
       "557  stand230.png      1\n",
       "\n",
       "[558 rows x 2 columns]>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "an = pd.read_csv('datapool.csv')\n",
    "an.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = io.imread(img_path)\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return (image, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "in_channel = 3\n",
    "num_classes = 2\n",
    "learning_rate = 1e-3\n",
    "batch_size = 32\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "dataset = CustomImageDataset(\n",
    "    csv_file=\"datapool.csv\",\n",
    "    root_dir=\"datapool\",\n",
    "    transform=transforms.ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "558\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [390, 168])\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GoogLeNet(\n",
       "  (conv1): BasicConv2d(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (conv2): BasicConv2d(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): BasicConv2d(\n",
       "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception3a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception3b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception4a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4c): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4d): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4e): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception5a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception5b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (aux1): None\n",
       "  (aux2): None\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model\n",
    "model = torchvision.models.googlenet(pretrained=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at epoch 0 is 1.241349098774103\n",
      "Cost at epoch 1 is 0.23748125823644492\n",
      "Cost at epoch 2 is 0.13176235284369725\n",
      "Cost at epoch 3 is 0.07983459281520201\n",
      "Cost at epoch 4 is 0.03885543108201371\n",
      "Cost at epoch 5 is 0.08584634612242763\n",
      "Cost at epoch 6 is 0.07030096241774467\n",
      "Cost at epoch 7 is 0.05371632340113418\n",
      "Cost at epoch 8 is 0.05353986002648106\n",
      "Cost at epoch 9 is 0.0555898763705045\n"
     ]
    }
   ],
   "source": [
    "# Train Network\n",
    "for epoch in range(num_epochs):\n",
    "    losses = []\n",
    "\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking accuracy on Training Set\n",
      "Got 369 / 390 with accuracy 94.62\n",
      "Checking accuracy on Test Set\n",
      "Got 147 / 168 with accuracy 87.50\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy on training to see how good our model is\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "        print(\n",
    "            f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\n",
    "        )\n",
    "\n",
    "    model.train()\n",
    "\n",
    "\n",
    "print(\"Checking accuracy on Training Set\")\n",
    "check_accuracy(train_loader, model)\n",
    "\n",
    "print(\"Checking accuracy on Test Set\")\n",
    "check_accuracy(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the activity prediction with dynamic data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import pafy\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from moviepy.editor import *\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_constant = 23\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resize to train data faster and to train data uniformly\n",
    "image_height, image_width = 64, 64\n",
    "max_images_per_class = 990\n",
    "\n",
    "dataset_directory = \"dummydata\"\n",
    "classes_list = [\"sitting\", \"standing\", \"walking\", \"falling\"]\n",
    "\n",
    "model_output_size = len(classes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_extraction(video_path):\n",
    "    # Empty List declared to store video frames\n",
    "    frames_list = []\n",
    "    \n",
    "    for filename in os.listdir(video_path):\n",
    "        frame = cv2.imread(os.path.join(video_path,filename))\n",
    "        if frame is not None:\n",
    "            # Resize the Frame to fixed Dimensions\n",
    "            resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "\n",
    "            # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
    "            normalized_frame = resized_frame / 255\n",
    "\n",
    "            # Appending the normalized frame into the frames list\n",
    "            frames_list.append(normalized_frame)\n",
    "            \n",
    "    return frames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "\n",
    "    # Declaring Empty Lists to store the features and labels values.\n",
    "    temp_features = [] \n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterating through all the classes mentioned in the classes list\n",
    "    for class_index, class_name in enumerate(classes_list):\n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "        \n",
    "        # Getting the list of video files present in the specific class name directory\n",
    "        files_list = os.listdir(os.path.join(dataset_directory, class_name))\n",
    "\n",
    "        # Iterating through all the files present in the files list\n",
    "        for file_name in files_list:\n",
    "            #print(file_name)\n",
    "            # Construct the complete video path\n",
    "            video_file_path = os.path.join(dataset_directory, class_name, file_name)\n",
    "            \n",
    "            # Calling the frame_extraction method for every video file path\n",
    "            frames = frames_extraction(video_file_path)\n",
    "\n",
    "            # Appending the frames to a temporary list.\n",
    "            temp_features.extend(frames)\n",
    "        \n",
    "        # Adding randomly selected frames to the features list\n",
    "        if(class_name == 'falling'):\n",
    "            max_images_per_class = 990\n",
    "        elif(class_name == 'sitting'):\n",
    "            max_images_per_class = 2050\n",
    "        elif(class_name == 'walking'):\n",
    "            max_images_per_class = 1100\n",
    "        else:\n",
    "            max_images_per_class = 1100\n",
    "        features.extend(random.sample(temp_features, max_images_per_class))\n",
    "\n",
    "        # Adding Fixed number of labels to the labels list\n",
    "        labels.extend([class_index] * max_images_per_class)\n",
    "        \n",
    "        # Emptying the temp_features list so it can be reused to store all frames of the next class.\n",
    "        temp_features.clear()\n",
    "\n",
    "    # Converting the features and labels lists to numpy arrays\n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels)  \n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data of Class: sitting\n",
      "Extracting Data of Class: standing\n",
      "Extracting Data of Class: walking\n",
      "Extracting Data of Class: falling\n",
      "(5240, 64, 64, 3)\n",
      "(5240,)\n"
     ]
    }
   ],
   "source": [
    "features, labels = create_dataset()\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_encoded_labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, test_size = 0.2, shuffle = True, random_state = seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 62, 62, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 60, 60, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 60, 60, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 57,668\n",
      "Trainable params: 57,028\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model Created Successfully!\n"
     ]
    }
   ],
   "source": [
    "# Let's create a function that will construct our model\n",
    "def create_model():\n",
    "\n",
    "    # We will use a Sequential model for model construction\n",
    "    model = Sequential()\n",
    "\n",
    "    # Defining The Model Architecture\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', input_shape = (image_height, image_width, 3)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(model_output_size, activation = 'softmax'))\n",
    "\n",
    "    # Printing the models summary\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Calling the create_model method\n",
    "model = create_model()\n",
    "\n",
    "print(\"Model Created Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open('model_structure.png')\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "839/839 [==============================] - 117s 138ms/step - loss: 1.2787 - accuracy: 0.4210 - val_loss: 2.4731 - val_accuracy: 0.3135\n",
      "Epoch 2/50\n",
      "839/839 [==============================] - 113s 135ms/step - loss: 1.1696 - accuracy: 0.4518 - val_loss: 2.4348 - val_accuracy: 0.2849\n",
      "Epoch 3/50\n",
      "839/839 [==============================] - 88s 105ms/step - loss: 1.1004 - accuracy: 0.5121 - val_loss: 2.2035 - val_accuracy: 0.4517\n",
      "Epoch 4/50\n",
      "839/839 [==============================] - 86s 102ms/step - loss: 1.0683 - accuracy: 0.5253 - val_loss: 1.9588 - val_accuracy: 0.4458\n",
      "Epoch 5/50\n",
      "839/839 [==============================] - 87s 104ms/step - loss: 1.0428 - accuracy: 0.5483 - val_loss: 1.9074 - val_accuracy: 0.3290\n",
      "Epoch 6/50\n",
      "839/839 [==============================] - 82s 98ms/step - loss: 0.9429 - accuracy: 0.6060 - val_loss: 1.9685 - val_accuracy: 0.5602\n",
      "Epoch 7/50\n",
      "839/839 [==============================] - 83s 99ms/step - loss: 0.9557 - accuracy: 0.6116 - val_loss: 3.1453 - val_accuracy: 0.4017\n",
      "Epoch 8/50\n",
      "839/839 [==============================] - 84s 100ms/step - loss: 0.9614 - accuracy: 0.6060 - val_loss: 0.9143 - val_accuracy: 0.6448\n",
      "Epoch 9/50\n",
      "839/839 [==============================] - 87s 103ms/step - loss: 0.9056 - accuracy: 0.6345 - val_loss: 1.6059 - val_accuracy: 0.4899\n",
      "Epoch 10/50\n",
      "839/839 [==============================] - 88s 105ms/step - loss: 0.9117 - accuracy: 0.6272 - val_loss: 1.9184 - val_accuracy: 0.5018\n",
      "Epoch 11/50\n",
      "839/839 [==============================] - 82s 98ms/step - loss: 0.8457 - accuracy: 0.6680 - val_loss: 1.4474 - val_accuracy: 0.5888\n",
      "Epoch 12/50\n",
      "839/839 [==============================] - 82s 98ms/step - loss: 0.8198 - accuracy: 0.6732 - val_loss: 1.0787 - val_accuracy: 0.5840\n",
      "Epoch 13/50\n",
      "839/839 [==============================] - 85s 101ms/step - loss: 0.8161 - accuracy: 0.6726 - val_loss: 0.7190 - val_accuracy: 0.7104\n",
      "Epoch 14/50\n",
      "839/839 [==============================] - 85s 101ms/step - loss: 0.7896 - accuracy: 0.6914 - val_loss: 0.8955 - val_accuracy: 0.6305\n",
      "Epoch 15/50\n",
      "839/839 [==============================] - 83s 99ms/step - loss: 0.8001 - accuracy: 0.6836 - val_loss: 2.2349 - val_accuracy: 0.4732\n",
      "Epoch 16/50\n",
      "839/839 [==============================] - 83s 98ms/step - loss: 0.7878 - accuracy: 0.6893 - val_loss: 0.7724 - val_accuracy: 0.7128\n",
      "Epoch 17/50\n",
      "839/839 [==============================] - 83s 99ms/step - loss: 0.7419 - accuracy: 0.7168 - val_loss: 0.9189 - val_accuracy: 0.6400\n",
      "Epoch 18/50\n",
      "839/839 [==============================] - 89s 107ms/step - loss: 0.8140 - accuracy: 0.6707 - val_loss: 0.8608 - val_accuracy: 0.6532\n",
      "Epoch 19/50\n",
      "839/839 [==============================] - 83s 99ms/step - loss: 0.7780 - accuracy: 0.6982 - val_loss: 0.8085 - val_accuracy: 0.7211\n",
      "Epoch 20/50\n",
      "839/839 [==============================] - 84s 100ms/step - loss: 0.7723 - accuracy: 0.7022 - val_loss: 1.3153 - val_accuracy: 0.5626\n",
      "Epoch 21/50\n",
      "839/839 [==============================] - 83s 99ms/step - loss: 0.7939 - accuracy: 0.6724 - val_loss: 0.6801 - val_accuracy: 0.7175\n",
      "Epoch 22/50\n",
      "839/839 [==============================] - 87s 104ms/step - loss: 0.7753 - accuracy: 0.7016 - val_loss: 1.1257 - val_accuracy: 0.5745\n",
      "Epoch 23/50\n",
      "839/839 [==============================] - 84s 100ms/step - loss: 0.7402 - accuracy: 0.7087 - val_loss: 0.6926 - val_accuracy: 0.7437\n",
      "Epoch 24/50\n",
      "839/839 [==============================] - 85s 101ms/step - loss: 0.7538 - accuracy: 0.7133 - val_loss: 0.8407 - val_accuracy: 0.6973\n",
      "Epoch 25/50\n",
      "839/839 [==============================] - 84s 100ms/step - loss: 0.7652 - accuracy: 0.6946 - val_loss: 1.0791 - val_accuracy: 0.6067\n",
      "Epoch 26/50\n",
      "839/839 [==============================] - 87s 104ms/step - loss: 0.7510 - accuracy: 0.7023 - val_loss: 0.6168 - val_accuracy: 0.7700\n",
      "Epoch 27/50\n",
      "839/839 [==============================] - 85s 101ms/step - loss: 0.7386 - accuracy: 0.7061 - val_loss: 0.7906 - val_accuracy: 0.6985\n",
      "Epoch 28/50\n",
      "839/839 [==============================] - 84s 100ms/step - loss: 0.7380 - accuracy: 0.7105 - val_loss: 0.6986 - val_accuracy: 0.7616\n",
      "Epoch 29/50\n",
      "839/839 [==============================] - 85s 101ms/step - loss: 0.7167 - accuracy: 0.7298 - val_loss: 0.6088 - val_accuracy: 0.7902\n",
      "Epoch 30/50\n",
      "839/839 [==============================] - 87s 104ms/step - loss: 0.7141 - accuracy: 0.7177 - val_loss: 0.9123 - val_accuracy: 0.6925\n",
      "Epoch 31/50\n",
      "839/839 [==============================] - 86s 103ms/step - loss: 0.7246 - accuracy: 0.7246 - val_loss: 0.5823 - val_accuracy: 0.7914\n",
      "Epoch 32/50\n",
      "839/839 [==============================] - 85s 101ms/step - loss: 0.6919 - accuracy: 0.7445 - val_loss: 0.5936 - val_accuracy: 0.7878\n",
      "Epoch 33/50\n",
      "839/839 [==============================] - 85s 102ms/step - loss: 0.7040 - accuracy: 0.7307 - val_loss: 1.0612 - val_accuracy: 0.6317\n",
      "Epoch 34/50\n",
      "839/839 [==============================] - 87s 104ms/step - loss: 0.6871 - accuracy: 0.7303 - val_loss: 0.7383 - val_accuracy: 0.7545\n",
      "Epoch 35/50\n",
      "839/839 [==============================] - 86s 103ms/step - loss: 0.7023 - accuracy: 0.7413 - val_loss: 0.7783 - val_accuracy: 0.7426\n",
      "Epoch 36/50\n",
      "839/839 [==============================] - 84s 100ms/step - loss: 0.7330 - accuracy: 0.7190 - val_loss: 0.7613 - val_accuracy: 0.7640\n",
      "Epoch 37/50\n",
      "839/839 [==============================] - 84s 100ms/step - loss: 0.6757 - accuracy: 0.7548 - val_loss: 0.9550 - val_accuracy: 0.7032\n",
      "Epoch 38/50\n",
      "839/839 [==============================] - 83s 99ms/step - loss: 0.7212 - accuracy: 0.7186 - val_loss: 0.8971 - val_accuracy: 0.7044\n",
      "Epoch 39/50\n",
      "839/839 [==============================] - 87s 104ms/step - loss: 0.6672 - accuracy: 0.7406 - val_loss: 0.6196 - val_accuracy: 0.7986\n",
      "Epoch 40/50\n",
      "839/839 [==============================] - 84s 101ms/step - loss: 0.6978 - accuracy: 0.7326 - val_loss: 0.6862 - val_accuracy: 0.7521\n",
      "Epoch 41/50\n",
      "839/839 [==============================] - 83s 99ms/step - loss: 0.7029 - accuracy: 0.7310 - val_loss: 0.5886 - val_accuracy: 0.7890\n",
      "Epoch 42/50\n",
      "839/839 [==============================] - 83s 99ms/step - loss: 0.7177 - accuracy: 0.7171 - val_loss: 0.7314 - val_accuracy: 0.7378\n",
      "Epoch 43/50\n",
      "839/839 [==============================] - 87s 104ms/step - loss: 0.6960 - accuracy: 0.7296 - val_loss: 0.7174 - val_accuracy: 0.7390\n",
      "Epoch 44/50\n",
      "839/839 [==============================] - 84s 100ms/step - loss: 0.6990 - accuracy: 0.7226 - val_loss: 0.5882 - val_accuracy: 0.7831\n",
      "Epoch 45/50\n",
      "839/839 [==============================] - 85s 102ms/step - loss: 0.7111 - accuracy: 0.7269 - val_loss: 0.6202 - val_accuracy: 0.7759\n",
      "Epoch 46/50\n",
      "839/839 [==============================] - 85s 101ms/step - loss: 0.6672 - accuracy: 0.7468 - val_loss: 0.6277 - val_accuracy: 0.7712\n"
     ]
    }
   ],
   "source": [
    "# Adding the Early Stopping Callback to the model which will continuously monitor the validation loss metric for every epoch.\n",
    "# If the models validation loss does not decrease after 15 consecutive epochs, the training will be stopped and the weight which reported the lowest validation loss will be retored in the model.\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 15, mode = 'min', restore_best_weights = True)\n",
    "\n",
    "# Adding loss, optimizer and metrics values to the model.\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "# Start Training\n",
    "model_training_history = model.fit(x = features_train, y = labels_train, epochs = 50, batch_size = 4 , shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-0068f2baecc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_evaluation_history\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1340\u001b[0m     \u001b[0mbase_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_api_gauge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'evaluate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1341\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'evaluate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1342\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1343\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'evaluate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'evaluate'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2590\u001b[0m     \u001b[1;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2591\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2592\u001b[1;33m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[0;32m   2593\u001b[0m                          \u001b[1;34m'training/testing. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2594\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "model_evaluation_history = model.evaluate(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a useful name for our model, incase you're saving multiple models (OPTIONAL)\n",
    "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
    "current_date_time_dt = dt.datetime.now()\n",
    "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
    "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
    "model_name = f'Model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
    "\n",
    "# Saving your Model\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(metric_name_1, metric_name_2, plot_name):\n",
    "  # Get Metric values using metric names as identifiers\n",
    "  metric_value_1 = model_training_history.history[metric_name_1]\n",
    "  metric_value_2 = model_training_history.history[metric_name_2]\n",
    "\n",
    "  # Constructing a range object which will be used as time \n",
    "  epochs = range(len(metric_value_1))\n",
    "  \n",
    "  # Plotting the Graph\n",
    "  plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
    "  plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
    "  \n",
    "  # Adding title to the plot\n",
    "  plt.title(str(plot_name))\n",
    "\n",
    "  # Adding legend to the plot\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trained_model(weights_path):\n",
    "   model = create_model()\n",
    "   model.load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_live_video(video_file_path, output_file_path, window_size):\n",
    "    \n",
    "    model = load_trained_model('Model___Date_Time_2021_05_03__13_03_12___Loss_0.5381714701652527___Accuracy_0.8129770755767822.h5')\n",
    "    # Initialize a Deque Object with a fixed size which will be used to implement moving/rolling average functionality.\n",
    "    predicted_labels_probabilities_deque = deque(maxlen = window_size)\n",
    "\n",
    "    # Reading the Video File using the VideoCapture Object\n",
    "\n",
    "    # Getting the width and height of the video \n",
    "    original_video_width = 720 #int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_video_height = 486 #int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Writing the Overlayed Video Files Using the VideoWriter Object\n",
    "    video_writer = cv2.VideoWriter(output_file_path, cv2.VideoWriter_fourcc('M', 'P', '4', 'V'), 24, (original_video_width, original_video_height))\n",
    "    for filename in os.listdir(video_file_path):\n",
    "        frame = cv2.imread(os.path.join(video_file_path,filename))\n",
    "        if frame is not None:\n",
    "        # Resize the Frame to fixed Dimensions\n",
    "            resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "\n",
    "            # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
    "            normalized_frame = resized_frame / 255\n",
    "\n",
    "            # Passing the Image Normalized Frame to the model and receiving Predicted Probabilities.\n",
    "            predicted_labels_probabilities = model.predict(np.expand_dims(normalized_frame, axis = 0))[0]\n",
    "\n",
    "            # Appending predicted label probabilities to the deque object\n",
    "            predicted_labels_probabilities_deque.append(predicted_labels_probabilities)\n",
    "\n",
    "            # Assuring that the Deque is completely filled before starting the averaging process\n",
    "            if len(predicted_labels_probabilities_deque) == window_size:\n",
    "\n",
    "                # Converting Predicted Labels Probabilities Deque into Numpy array\n",
    "                predicted_labels_probabilities_np = np.array(predicted_labels_probabilities_deque)\n",
    "\n",
    "                # Calculating Average of Predicted Labels Probabilities Column Wise \n",
    "                predicted_labels_probabilities_averaged = predicted_labels_probabilities_np.mean(axis = 0)\n",
    "\n",
    "                # Converting the predicted probabilities into labels by returning the index of the maximum value.\n",
    "                predicted_label = np.argmax(predicted_labels_probabilities_averaged)\n",
    "\n",
    "                # Accessing The Class Name using predicted label.\n",
    "                predicted_class_name = classes_list[predicted_label]\n",
    "\n",
    "                # Overlaying Class Name Text Ontop of the Frame\n",
    "                cv2.putText(frame, predicted_class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                print(predicted_class_name)\n",
    "\n",
    "        # Writing The Frame\n",
    "        video_writer.write(frame)\n",
    "\n",
    "\n",
    "        # cv2.imshow('Predicted Frames', frame)\n",
    "\n",
    "        # key_pressed = cv2.waitKey(10)\n",
    "\n",
    "        # if key_pressed == ord('q'):\n",
    "        #     break\n",
    "\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "    # Closing the VideoCapture and VideoWriter objects and releasing all resources held by them. \n",
    "    #video_reader.release()\n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 62, 62, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 60, 60, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 60, 60, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 57,668\n",
      "Trainable params: 57,028\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-4f1f362e0056>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# Calling the predict_on_live_video method to start the Prediction.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mpredict_on_live_video\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_video_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_video_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Play Video File in the Notebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-e4adcfd882bf>\u001b[0m in \u001b[0;36mpredict_on_live_video\u001b[1;34m(video_file_path, output_file_path, window_size)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m# Passing the Image Normalized Frame to the model and receiving Predicted Probabilities.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mpredicted_labels_probabilities\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalized_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;31m# Appending predicted label probabilities to the deque object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "output_directory = 'Predicted_Videos'\n",
    "video_title = 'prediction'\n",
    "input_video_file_path = 'dummydata/falling/fall40'\n",
    "#input_video_file_path = 'Data4' \n",
    "# Setting sthe Widow Size which will be used by the Rolling Averge Proces\n",
    "window_size = 1\n",
    "\n",
    "# Construting The Output YouTube Video Path\n",
    "output_video_file_path = f'{output_directory}/{video_title} -Output-WSize {window_size}.mp4'\n",
    "\n",
    "# Calling the predict_on_live_video method to start the Prediction.\n",
    "predict_on_live_video(input_video_file_path, output_video_file_path, window_size)\n",
    "\n",
    "# Play Video File in the Notebook\n",
    "#VideoFileClip(output_video_file_path).ipython_display(width = 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_average_predictions(video_file_path, predictions_frames_count):\n",
    "    \n",
    "    # Initializing the Numpy array which will store Prediction Probabilities\n",
    "    predicted_labels_probabilities_np = np.zeros((predictions_frames_count, model_output_size), dtype = np.float)\n",
    "\n",
    "    frame_counter = 0\n",
    "    for filename in os.listdir(video_file_path):\n",
    "        \n",
    "        frame = cv2.imread(os.path.join(video_file_path,filename))\n",
    "        \n",
    "        # Setting Frame Position\n",
    "        #video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    "\n",
    "        # Reading The Frame\n",
    "        #_ , frame = video_reader.read()\n",
    "\n",
    "        # Resize the Frame to fixed Dimensions\n",
    "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "        \n",
    "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
    "        normalized_frame = resized_frame / 255\n",
    "\n",
    "        # Passing the Image Normalized Frame to the model and receiving Predicted Probabilities.\n",
    "        predicted_labels_probabilities = model.predict(np.expand_dims(normalized_frame, axis = 0))[0]\n",
    "\n",
    "        # Appending predicted label probabilities to the deque object\n",
    "        predicted_labels_probabilities_np[frame_counter] = predicted_labels_probabilities\n",
    "        frame_counter = frame_counter + 1\n",
    "    # Calculating Average of Predicted Labels Probabilities Column Wise \n",
    "    predicted_labels_probabilities_averaged = predicted_labels_probabilities_np.mean(axis = 0)\n",
    "\n",
    "    # Sorting the Averaged Predicted Labels Probabilities\n",
    "    predicted_labels_probabilities_averaged_sorted_indexes = np.argsort(predicted_labels_probabilities_averaged)[::-1]\n",
    "\n",
    "    # Iterating Over All Averaged Predicted Label Probabilities\n",
    "    for predicted_label in predicted_labels_probabilities_averaged_sorted_indexes:\n",
    "\n",
    "        # Accessing The Class Name using predicted label.\n",
    "        predicted_class_name = classes_list[predicted_label]\n",
    "\n",
    "        # Accessing The Averaged Probability using predicted label.\n",
    "        predicted_probability = predicted_labels_probabilities_averaged[predicted_label]\n",
    "\n",
    "        print(f\"CLASS NAME: {predicted_class_name}   AVERAGED PROBABILITY: {(predicted_probability*100):.2}\")\n",
    "    \n",
    "    # Closing the VideoCapture Object and releasing all resources held by it. \n",
    "    #video_reader.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASS NAME: walking   AVERAGED PROBABILITY: 9.7\n",
      "CLASS NAME: sitting   AVERAGED PROBABILITY: 9.6\n",
      "CLASS NAME: standing   AVERAGED PROBABILITY: 9.5\n",
      "CLASS NAME: falling   AVERAGED PROBABILITY: 9.2\n"
     ]
    }
   ],
   "source": [
    "input_video_file_path = 'Data3' \n",
    "#input_video_file_path = 'dummydata/falling/fall40'\n",
    "# Calling The Make Average Method To Start The Process\n",
    "make_average_predictions(input_video_file_path, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity detection using sound data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Module 1 split sound data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.utils import make_chunks\n",
    "\n",
    "input_path = 'soundData\\\\standing'\n",
    "count = 0\n",
    "for filename in os.listdir(input_path):\n",
    "        #frame = cv2.imread(os.path.join(video_path,filename))\n",
    "\n",
    "    myaudio = AudioSegment.from_file(os.path.join(input_path,filename) , \"wav\") \n",
    "    chunk_length_ms = 1000 # pydub calculates in millisec\n",
    "    chunks = make_chunks(myaudio, chunk_length_ms) #Make chunks of one sec\n",
    "\n",
    "    #Export all of the individual chunks as wav files\n",
    "    count += 1\n",
    "    #folder_name = 'chunkedData\\\\falling\\\\fall' + str(count) + '\\\\'\n",
    "    folder_name = 'chunkedData\\\\standing\\\\'\n",
    "    path = os.path.join(folder_name,'stand' + str(count))\n",
    "    os.mkdir(path)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk_name = \"chunk{0}.wav\".format(i)\n",
    "        #print (folder_name+chunk_name)\n",
    "        chunk.export(os.path.join(path,chunk_name), format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as idp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_directory = 'chunkedData'\n",
    "output_directory = 'soundImages'\n",
    "n_ftt = 2048\n",
    "hop_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectograms(sound_path, output_path):\n",
    "\n",
    "    count = 0\n",
    "    for filename in os.listdir(sound_path):\n",
    "        signal, sr = librosa.load(os.path.join(sound_path,filename))\n",
    "        #signal, sr = librosa.load(audio_file)\n",
    "        #MFCCs\n",
    "        #important features like formant and spectural envolope\n",
    "        count += 1\n",
    "        path = os.path.join(output_path, str(count))\n",
    "        mfcc = librosa.feature.mfcc(signal, n_fft=n_ftt, hop_length=hop_length, n_mfcc=12)\n",
    "        librosa.display.specshow(mfcc, sr=sr, hop_length=hop_length)\n",
    "        plt.savefig(path + '.png', bbox_inches='tight')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADrCAYAAABXYUzjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAJqklEQVR4nO3dzY4cVxkG4FPd0zOemFhxoggkUBASSCy4DK6Bu2DLRcCWG+AiWCL2rLiFLJAiGRnFwTEzPd3FwkJIYer73F00rxyeZ+ma+jt16p2yZZ13mud5APC/t0lfAMD/KwEMECKAAUIEMECIAAYIEcAAIVen/PAnT2/nz55/ePpZpun0fd7Vmv9G113Xt/G/6F3yWXTex/FcO17v4z2/r9Y8qws/pz//5cVf53n+9Jt/flIAf/b8w/HHX/7i0W3TZvnmp+32lNP8h/lYDM58PP/AU/0XgON+3+x+/l8gqvHqlOPRHbu55+nq/Gc1Pxzq7Yfl7fOxfo7dWFf33I1Xde7Nblfu21oxP4/FeK6Ze2/3v9z8q8azu+5uHlS6Z1Xd83H/cPa+7+KjX/3288f+3D9BAIQIYIAQAQwQIoABQgQwQIgABggRwAAhAhggRAADhAhggBABDBAigAFCBDBAiAAGCBHAACECGCDkpAXZK+Xi0d0C4s2C7eUi4cfLNTysXoy70izUXS16vXZx6PK8zaLq9c7nL6a9dqHu+aGYY814VeeuFpF/u+8lF9ZfseB/905VC9g399zZrFjUv/ombMe6e6eK29rcXJf7TkXbxryiTcMXMECIAAYIEcAAIQIYIEQAA4QIYIAQAQwQIoABQgQwQIgABggRwAAhAhggRAADhAhggBABDBAigAFCBDBAiAAGCDmtkmia2qqTx3Q1N13dzPaCtS+XctzvL3j0+vfmqsqiC1YlnTN33tU8lq+7q8iZiuqpVRVNoxmT6XJzs50DRd1RO3u66y7mUPc+1lmw7nuxfJbNc15Xs1Qc9yJHBaAlgAFCBDBAiAAGCBHAACECGCBEAAOECGCAEAEMECKAAUIEMECIAAYIEcAAIQIYIEQAA4QIYIAQAQwQclojxjwvrna/2S0favrgtj5u04gxz0ULw9St37+i0aBoDRijbniYmhX0u6aFVa0WleaexmhW/i+uu7vnNar51e98/ndG2+KxZu42l9XP7RWqRoxmrNuGm0OxvWnT2Nxcl9sra8arvOYL8gUMECKAAUIEMECIAAYIEcAAIQIYIEQAA4QIYIAQAQwQIoABQgQwQIgABggRwAAhAhggRAADhAhggBABDBBycs3AcWE1/OlYrPy/crX5uTh20qrWiqYO4VL3PI2mwaE770IjyhhjzPv62G0FRKUZ6+q6u+dUtSG0jRhd20bVmNHsW13Xmuc0xiifxdo2lura2uaJ7rqrXc/ec4zD3X197OKeNt0cKfgCBggRwAAhAhggRAADhAhggBABDBAigAFCBDBAiAAGCBHAACECGCBEAAOECGCAEAEMECKAAUIEMECIAAYIObkRY8m80JQxxhjHZpX7tnWg2rdrJLigpXaQMcbYXDX31IxJdexV9zzXbQfVed/+QNE70DQpTJvzOwuOXdtGoWthqObfdsXc7FTvzNsfOP+e+5MXzSZdgU3XbFIdu7nncoasaDbpdBk0FZvXvI++gAFCBDBAiAAGCBHAACECGCBEAAOECGCAEAEMECKAAUIEMECIAAYIEcAAIQIYIEQAA4QIYIAQAQwQIoABQk5qxJiPx3F4c7e4bXG/uW5CmKZ6pfty32Y1+qlqpiiueYy+HaJsvTju6mM3q/dXzQHVWI9RNwN0K/93TR5z0YhxuLsv952aRoNS1zpQjMnh/qHcdXu9/BocdvVz7J5F5ZJzt3XJJpnqWezrZ1HpcqLLmU0x96erpq2luKe2RabgCxggRAADhAhggBABDBAigAFCBDBAiAAGCBHAACECGCBEAAOECGCAEAEMECKAAUIEMECIAAYIEcAAIQIYIOSkRozK9sn14rauhWEULQurVS0MzXnLRoIxxjQt//7q9t12zRO7yzUtlPt2z2pevq7t7U197OK6umaJtj2ieM5Vi0e372rFHFmleA5vN5//TrUtH92xd8uxsrlZzolWc965GZPK9smTs/ddwxcwQIgABggRwAAhAhggRAADhAhggBABDBAigAFCBDBAiAAGCBHAACECGCBEAAOECGCAEAEMECKAAUIEMEDISY0Y02Yzrp7ennyStY0Dx4dDcez6d8hc7Fu2ZYwxNptdub0878qGh83u/HNXbQnVWI7RjNcYqxpGyl/3XdvBsbnu+syl6Xr5NVjTLDHGGFNVMJJstSi0jSqhz7Z5NO/Usb6w42F5Dt397cv62NPyvN807TYVX8AAIQIYIEQAA4QIYIAQAQwQIoABQgQwQIgABggRwAAhAhggRAADhAhggBABDBAigAFCBDBAiAAGCBHAACEnNWKMaRrT9vHV3ze75UNNzYrx3cr/036/vLFbvX+3vIr+XKyQP0bfHlGvhF9f15qWkG48x1jevl14fu+sG+9K0dLQ9Te04zUtX9e6RpamIaQ47xjNszp297T8XnT3dNw/1McuVO/yGGMxA/59gOUx6d65ao6smntjjKviuqfmnitTMwcqvoABQgQwQIgABggRwAAhAhggRAADhAhggBABDBAigAFCBDBAiAAGCBHAACECGCBEAAOECGCAEAEMECKAAUIEMEDIST0cr794Nf70mz88um3/1XIFyuaqrk+Zdpf7PfDw6vxqls72dvm6D2+6kp3a9ce7xW2337su963qat68uC/3vX9Z1D+N+ll2z/H64+Xp1s2RbjyrZ3HzrB6vypuXd/V5b+p73myX7+v+y/Pn5rSrx+v+ZX3seb88ntvbunLo6llTMbZfrlLaf1VXEh3eNJVFZ553jDFuvrs8D57/5Fm57+52+X1cU3nlCxggRAADhAhggBABDBAigAFCBDBAiAAGCBHAACECGCBEAAOECGCAEAEMECKAAUIEMECIAAYIEcAAIQIYIOSkRowvnv1o/Prnv3t02+5mebX5+VivVP+wr1sYHvbnNwdc7ZZvcdrUv3+OD/Xq/NV13zy9LffdbutWgbuv3yxve728bYz6vm5/9p1y3+snN+X2yjzXrRV3r/+xuK1rFbi+ra+rmmNfv/p7uW/l5qf1czzc13PzcFieQ90cqMZzf1c3m0xTPbevrpffi4funpr3dXO1fF/b3XKzxBj9mJx73jHqOfaDH3+/3PejTz5Y3HZs8m2MMcbvP3z0j30BA4QIYIAQAQwQIoABQgQwQIgABggRwAAhAhggRAADhAhggBABDBAigAFCBDBAiAAGCBHAACECGCBkmud3WEz4Xz88TS/GGJ9f7nIAvpV+OM/zp9/8w5MCGID/Hv8EARAigAFCBDBAiAAGCBHAACECGCBEAAOECGCAEAEMEPJPe3AmsNLKn4gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_spectograms('chunkedData\\\\sitting\\\\sit1', 'soundImages\\\\sitting\\\\sit1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data of Class: sitting\n",
      "Extracting Data of Class: standing\n",
      "Extracting Data of Class: walking\n",
      "Extracting Data of Class: falling\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAADrCAYAAABXYUzjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAJkUlEQVR4nO3dQZLkRhkF4JS6q9sDYXBAeGlYcADuwi24ABuu4VtwBy7AhhUrNl54ZQIIDB5PV7fEwiww0fr/qUqKF8D3La2RlFKm3lQ4JvIt+74PAP7z1vQAAP5fCWCAEAEMECKAAUIEMECIAAYIub/kD//wux/sn3z04avHlrEcnreP+p+6Vef+4w8cu+W/omuGNaUZd/XPA5flhgPrLl2Me2aeu3NTbvquuzVQ/IFbjqv7p6mp73V2jdwso95jKn77+Rd/2Pf943/97xcF8CcffTh+/fOfvT6G5fjH9L5v5XWrc8cYY6zFE243/HCr+44x1vu7w2N7M679+aU8vp3Px/c9ncpzpzTPXL3vmXnuzu3e562sp/oTWdZ67e5b8VzdGineyXJ3vPZmx7W/1Gsz9b1u3biatVuNu7v2Wrzv9aGP0Y9+8elnr57bngnATQhggBABDBAigAFCBDBAiAAGCBHAACECGCBEAAOECGCAEAEMECKAAUIEMECIAAYIEcAAIQIYIOSiDdkr5ebRzQbOS7Gxeav5K6Ta+LzdQHzU49qKa2/n5/ra3Wbv1abr3cbTzWbcM5b743tX76O9bvOul26JVBt9d5vMV/ftNjZvnnlqU/Wt2EB8cn1V3+TsZu/Vvbs1Ul17nZjHzrLX167m8fntu6vv6xcwQIgABggRwAAhAhggRAADhAhggBABDBAigAFCBDBAiAAGCBHAACECGCBEAAOECGCAEAEMECKAAUIEMECIAAYIuaySaO8rWF49bS3qYsYYS1MNtFd1MxO6Z1nWpm5mZlxdvUo1M90U3Oh9fXPp66unqlqXa9bVe+sqmrZi/U1WElWW++vnqbvvVj3TqKt/uoqwtaksqp5qe+m+uetrh7rvsbp2d271vmfG7BcwQIgABggRwAAhAhggRAADhAhggBABDBAigAFCBDBAiAAGCBHAACECGCBEAAOECGCAEAEMECKAAUIEMEDIRY0Yy7KM9XR69Vi303153WaH/WU53q1+O5/rixc7/9+9eazv27UhFK0Da9Mq0O7A3zQalKprT+zeP8YY6/r6/L+X5+JYsxLb5omq4aF75vV4rrq1OU71wMvmiZm5aNpHRtMysz0dT0bVXDLGmFpD63pZCc8lqpz45ubH415P9ftc3lzfplEO6eozAZgigAFCBDBAiAAGCBHAACECGCBEAAOECGCAEAEMECKAAUIEMECIAAYIEcAAIQIYIEQAA4QIYIAQAQwQctH29Pu+9w0UV9ibNo2qDaHbjb4qDuju26naDqrGgTEmG0QmGgmWrWn56NoQivfdndu2WlTndvM8ju/dPdItbefjdbB2bRvFPC/r9S0MY7zHPFe6Npfi2kvX5DGhXX/n69/ZVHtJwS9ggBABDBAigAFCBDBAiAAGCBHAACECGCBEAAOECGCAEAEMECKAAUIEMECIAAYIEcAAIQIYIEQAA4QIYICQixoxxjLGct/s4n+Fbpf85XR8fGZn/65lYd/qVotql/y+qWOi1eKGrQJL19LQPFdlfXy4yXXHuF0Lw8u7p/q+W73+qtaUcbrs8/tn3bg6M+uvbXMp3snyeH1+zDbYzOi+52v5BQwQIoABQgQwQIgABggRwAAhAhggRAADhAhggBABDBAigAFCBDBAiAAGCBHAACECGCBEAAOECGCAEAEMEHLZlvzbPl6+ntuJ/zVla8CoWwe6c6+97hhj7HvTmPF8vEN/2zjQjHtZJhozimvPNCGMMepxN+9zezpuGJkd160aC7bzuT7+fH0jy4yuEWNm/XVrr/suqnWwFd/MGHOtF12bSzXutTm3bAFp1n3FL2CAEAEMECKAAUIEMECIAAYIEcAAIQIYIEQAA4QIYIAQAQwQIoABQgQwQIgABggRwAAhAhggRAADhAhggJDLGjGWZaz39c7xr5porRhjjP3peMf5rtWiaofonqVrWajuPNsqMNP0UbYhTM5F1Rywdy0MVRvC5LiWcjZq1TzfPT6U5949Xn/tmRaQblxlg8Oo1+f6cLpqTO+japEZo/4uum9q5ntemnOXImdmulj8AgYIEcAAIQIYIEQAA4QIYIAQAQwQIoABQgQwQIgABggRwAAhAhggRAADhAhggBABDBAigAFCBDBAiAAGCLmwEeN45/iZnf+75omqHaLb+X8/n48PNi0MVfvDGPUO/V2jxTrRhjCjayTo5qrsnWjaScp53ubGVc5lM67yvtc0wHzr3hN9CcW4u/dxt9af9vRzFWaaJ+6K5+pyYkb3XZQm2lz8AgYIEcAAIQIYIEQAA4QIYIAQAQwQIoABQgQwQIgABggRwAAhAhggRAADhAhggBABDBAigAFCBDBAiAAGCLmsEaNQ7dC/LHXO72NiN/rGejodH3toWgOaRowZ2/m5PF7t0N+2Q4R0jQVVe0nXPtK1DpTvZK2vvRbrc7Y5Yi9aLfamzWW5O167Y3INVPeebZ6o1m73zZVzNdNa0ei+qeW+yJGJnPALGCBEAAOECGCAEAEMECKAAUIEMECIAAYIEcAAIQIYIEQAA4QIYIAQAQwQIoABQgQwQIgABggRwAAhAhggRAADhFxUSfT1n/42fver37x67OXpuHple64rTp7+WNfzvLwt6lPO9bWX03HVyN2bukqkuu8YY6z3RQ3Tqf677fRhfe+H7x9PzfZSP/NeHD9/WT/T3Zt63NUzd/NczVV3bqcaV/dM1Tvp1le3Rird+jt/efxddOc+/KD+tKv39fL2+Fseo/6muvO7dV/NRTeP3birueyeqTr3/nsqiQD+6whggBABDBAigAFCBDBAiAAGCBHAACECGCBEAAOECGCAEAEMECKAAUIEMECIAAYIEcAAIQIYIEQAA4Rc1Ijx+eOPxi9/8umrx06PD4fnrff1jvH3p2b3/rvj8++aa1denus2g9Pj6eprby/17vxv//pVefyrP//l8Niy1n9v3hdz8fDmsTz35alpJ3m5vgFiXYsGkaVr4rh+nrdmnqt38vidD8pzu7Vbva+nt09T1668++rr8vj53fG9l2Kexhjj+VyvkWqet61uGKnmopvH7ru4K3Kks94fX3t7rr/1McYYv//p69e9dkAAzBHAACECGCBEAAOECGCAEAEMECKAAUIEMECIAAYIEcAAIQIYIEQAA4QIYIAQAQwQIoABQgQwQMiy7/UGyd/6w8vyxRjjs9sNB+B/0o/3ff/4X//jRQEMwL+P/wUBECKAAUIEMECIAAYIEcAAIQIYIEQAA4QIYIAQAQwQ8ncQ/F1kwG3K1gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_sound_dataset():\n",
    "    # Iterating through all the classes mentioned in the classes list\n",
    "    for class_index, class_name in enumerate(classes_list):\n",
    "    #class_name = 'sitting'\n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "\n",
    "        # Getting the list of video files present in the specific class name directory\n",
    "        files_list = os.listdir(os.path.join(sound_directory, class_name))\n",
    "        output_list = os.listdir(os.path.join(output_directory, class_name))\n",
    "        # Iterating through all the files present in the files list\n",
    "        for file_name in files_list:\n",
    "            #print(file_name)\n",
    "            # Construct the complete video path\n",
    "            sound_file_path = os.path.join(sound_directory, class_name, file_name)\n",
    "            sound_output_path = os.path.join(output_directory, class_name, file_name)\n",
    "            os.mkdir(sound_output_path)\n",
    "            # Calling the frame_extraction method for every video file path\n",
    "            create_spectograms(sound_file_path, sound_output_path)\n",
    "create_sound_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "\n",
    "    # Declaring Empty Lists to store the features and labels values.\n",
    "    temp_features = [] \n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterating through all the classes mentioned in the classes list\n",
    "    for class_index, class_name in enumerate(classes_list):\n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "        \n",
    "        # Getting the list of video files present in the specific class name directory\n",
    "        files_list = os.listdir(os.path.join(output_directory, class_name))\n",
    "\n",
    "        # Iterating through all the files present in the files list\n",
    "        for file_name in files_list:\n",
    "            #print(file_name)\n",
    "            # Construct the complete video path\n",
    "            video_file_path = os.path.join(output_directory, class_name, file_name)\n",
    "            \n",
    "            # Calling the frame_extraction method for every video file path\n",
    "            frames = frames_extraction(video_file_path)\n",
    "\n",
    "            # Appending the frames to a temporary list.\n",
    "            temp_features.extend(frames)\n",
    "        \n",
    "        # Adding randomly selected frames to the features list\n",
    "        if(class_name == 'falling'):\n",
    "            max_images_per_class = 200\n",
    "        elif(class_name == 'sitting'):\n",
    "            max_images_per_class = 1000\n",
    "        elif(class_name == 'walking'):\n",
    "            max_images_per_class = 500\n",
    "        else:\n",
    "            max_images_per_class = 500\n",
    "        features.extend(random.sample(temp_features, max_images_per_class))\n",
    "\n",
    "        # Adding Fixed number of labels to the labels list\n",
    "        labels.extend([class_index] * max_images_per_class)\n",
    "        \n",
    "        # Emptying the temp_features list so it can be reused to store all frames of the next class.\n",
    "        temp_features.clear()\n",
    "\n",
    "    # Converting the features and labels lists to numpy arrays\n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels)  \n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data of Class: sitting\n",
      "Extracting Data of Class: standing\n",
      "Extracting Data of Class: walking\n",
      "Extracting Data of Class: falling\n",
      "(2200, 64, 64, 3)\n",
      "(2200,)\n"
     ]
    }
   ],
   "source": [
    "features, labels = create_dataset()\n",
    "print(features.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
